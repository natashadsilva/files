{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build-metro-application\n",
    "\n",
    "Builds metro appliction that accepts Kafka messages from the edge(s). \n",
    "\n",
    "Aggregates/Analyze messages \n",
    "- push to storage\n",
    "- generate events \n",
    "- send notifcations\n",
    "- deep analysis\n",
    "- host views to monitor the 'goings on'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamsx.eventstreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3, time, json, os, sys, collections, warnings, ast\n",
    "import numpy as np\n",
    "\n",
    "from streamsx.topology.topology import Topology\n",
    "from streamsx.topology.schema import CommonSchema\n",
    "from streamsx.topology.context import submit, ContextTypes\n",
    "import streamsx.eventstreams as eventstreams\n",
    "from streamsx.rest_primitives import Instance\n",
    "from streamsx import rest\n",
    "from streamsx.topology import context\n",
    "\n",
    "if 'scripts' not in sys.path:\n",
    "    sys.path.insert(0, 'scripts')\n",
    "import digit_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add credentials for the IBM Streams service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings()\n",
    "# Cell to grab Streams instance config object and REST reference\n",
    "from icpd_core import icpd_util\n",
    "STREAMS_INSTANCE_NAME = \"<INSERT-STREAMS-INSTANCE-NAME-HERE>\"\n",
    "streams_cfg=icpd_util.get_service_instance_details(name=STREAMS_INSTANCE_NAME)\n",
    "streams_cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "streams_instance = Instance.of_service(streams_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the EventStreams topics to access \n",
    "UNCERTAIN_PREDICTIONS_EVENTSTREAMS_TOPIC = 'UncertainPredictions'\n",
    "METRICS_EVENTSTREAMS_TOPIC = 'ClassificationMetrics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add IBM eventstreams credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eventstreams for uncertain predictions \n",
    "\n",
    "uncertain_eventstreams_credentials_json = getpass.getpass('Your Event Streams credentials:')\n",
    "uncertain_eventstreams_credentials = eventstreams.configure_connection(streams_instance, name='UNCERTAIN', credentials=uncertain_eventstreams_credentials_json)\n",
    "uncertain_eventstreams_credentials = 'UNCERTAIN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eventstreams for all metrics\n",
    "\n",
    "metrics_eventstreams_credentials_json = getpass.getpass('Your Event Streams credentials:')\n",
    "metrics_eventstreams_credentials = eventstreams.configure_connection(streams_instance, name='METRICS', credentials=metrics_eventstreams_credentials_json)\n",
    "metrics_eventstreams_credentials = 'METRICS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlideWindow(object):\n",
    "    \"\"\" Window with slide_length elements. \n",
    "    \n",
    "    Window fills, intial output will have less than slide_length.\n",
    "    \n",
    "    Args:\n",
    "        slide_length: maximum number of elements in window.\n",
    "        \n",
    "    Returns:\n",
    "        list of up to 25 of the last tups input.\n",
    "    \"\"\"\n",
    "    def __init__(self, slide_length:int=25):\n",
    "        self.slide_length = slide_length\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.chunk = collections.deque(maxlen=self.slide_length)\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        # __enter__ and __exit__ must both be defined.\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, tup) -> list:\n",
    "        self.chunk.append(tup)\n",
    "        return list(self.chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convert_tuples(object):\n",
    "    \n",
    "    def __call__(self, tup):\n",
    "        # Unbox the stream from streams flow\n",
    "        if 'metrics_json' in tup:\n",
    "            string_tup = tup['metrics_json']\n",
    "            \n",
    "            return str(string_tup)\n",
    "\n",
    "        elif 'uncertain_metrics_json' in tup:\n",
    "            string_tup = tup['uncertain_metrics_json']            \n",
    "            string_tup = json.loads(string_tup)\n",
    "        \n",
    "            # Convert from streams flow types into python types \n",
    "            string_tup['result_class'] = int(string_tup['result_class']) # float -> int\n",
    "            string_tup['predictions'] = ast.literal_eval(string_tup['predictions']) # String -> List\n",
    "            string_tup['image'] = ast.literal_eval(string_tup['image']) # String -> List\n",
    "            string_tup['prepared_image'] = np.reshape(string_tup['image'], (28, 28)).tolist() # reshape 784 len List into 28 x 28\n",
    "    \n",
    "            return json.dumps(string_tup)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you wish to use Kafka instead of IBM eventstreams, uncomment and fill in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To learn more, go to https://streamsxkafka.readthedocs.io/en/latest/ \n",
    "\n",
    "# !pip install --user streamsx.kafka>=1.9.0\n",
    "# import streamsx.kafka as kafka\n",
    "\n",
    "# consumerProperties = dict()\n",
    "# consumerProperties['bootstrap.servers'] = ...,\n",
    "# consumerProperties['fetch.min.bytes'] = ...,\n",
    "# consumerProperties['max.partition.fetch.bytes'] = ...,\n",
    "# consumerProperties['security.protocol'] = ...,\n",
    "# consumerProperties['sasl.jaas.config'] = ...\n",
    "\n",
    "# # Certain\n",
    "# consumer_certain = kafka.KafkaConsumer(config=consumerProperties,\n",
    "#                          topic='<YOUR_TOPIC>',\n",
    "#                          schema=CommonSchema.Json)\n",
    "\n",
    "# # Uncertain\n",
    "# consumer_uncertain = kafka.KafkaConsumer(config=consumerProperties,\n",
    "#                          topic='<YOUR_TOPIC>',\n",
    "#                          schema=CommonSchema.Json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you wish to use Kafka instead of IBM eventstreams, uncomment the relevant lines in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings()\n",
    "def build_metro() -> Topology:\n",
    "    \"\"\" metro application subscribing to two topics \n",
    "    \n",
    "    * Subscribed topics are reflected out view.\n",
    "    * Metrics are windowed\n",
    "    \n",
    "    Returns:\n",
    "        Topology of the application. \n",
    "    \"\"\"\n",
    "    topo = Topology('EdgeMetroSubscribe')\n",
    "\n",
    "    # COLLECT METRICS \n",
    "    from_evstr1 = eventstreams.subscribe(topo, schema=CommonSchema.Json, topic=METRICS_EVENTSTREAMS_TOPIC, credentials=metrics_eventstreams_credentials)\n",
    "    ## --- If using kafka, comment out the above line and use the following line instead ---\n",
    "    # from_evstr1 = topo.source(consumer_certain)\n",
    "    \n",
    "    from_evstr1_clean = from_evstr1.map(convert_tuples())\n",
    "    metrics_view = from_evstr1_clean.view(name=\"ClassificationMetrics\")\n",
    "    # from_evstr1_clean.print(name=\"ClassificationMetrics\")\n",
    "    \n",
    "    # WINDOW METRICS (Includes both certain and uncertain data)\n",
    "    windowSlide = from_evstr1_clean.map(SlideWindow())\n",
    "    metrics_windowSlide_view = windowSlide.view(name=\"WindowUncertain\")\n",
    "    # windowSlide.print(name=\"windowPrint\")\n",
    "    \n",
    "    # COLLECT UNCERTAIN METRICS\n",
    "    from_evstr2 = eventstreams.subscribe(topo, schema=CommonSchema.Json, topic=UNCERTAIN_PREDICTIONS_EVENTSTREAMS_TOPIC, credentials=uncertain_eventstreams_credentials)\n",
    "    ## --- If using kafka, comment out the above line and use the following line instead ---\n",
    "    # from_evstr2 = topo.source(consumer_uncertain)\n",
    "    \n",
    "    from_evstr2_clean = from_evstr2.map(convert_tuples())\n",
    "    un_certrain_metrics_view = from_evstr2_clean.view(name=\"UncertainPredictions\")\n",
    "    # from_evstr2_clean.print(name=\"uncertainPrint\")\n",
    "\n",
    "    return metrics_view, metrics_windowSlide_view, un_certrain_metrics_view, topo\n",
    "\n",
    "\n",
    "\n",
    "metrics_view, metrics_windowSlide_view, un_certrain_metrics_view, topo = build_metro()\n",
    "result = digit_support.submitToStreams(topo, streams_cfg)\n",
    "result['return_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the views that we've got up...\n",
    "time.sleep(15)   # give the applications time to wake up collect some images.....\n",
    "digit_support.display_views(streams_instance, job_name=\"EdgeMetroSubscribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the view and display sample data\n",
    "queue = un_certrain_metrics_view.start_data_fetch()\n",
    "try:\n",
    "    json_val = queue.get()\n",
    "    val = json.loads(json_val)\n",
    "    print('Predicted digit is {}'.format(val['result_class']))\n",
    "    print('Predicted probability is {}\\n'.format(val['result_probability']))\n",
    "    print(val)\n",
    "finally:\n",
    "    un_certrain_metrics_view.stop_data_fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor from metro. \n",
    "\n",
    "Once the metro is up and running the render-metro-views.ipynb notebook can monitor and enhance the processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
